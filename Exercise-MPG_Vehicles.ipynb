{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.1. Datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "#librerías para graficar\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "#tensorfloy\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estima la eficiencia de combustible de un automóvil\n",
    "# Usando el dataset Auto MPG, crea el modelo de estimación para la eficiencia de combustible a finales de 1970s y comienzos de 1980s.\n",
    "# Usa tf.keras API. Para más detalles revisa la guía de Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#la fuente de los datos\n",
    "dataset_path = \"http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargando los datos en un Pandas DataFrame\n",
    "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',\n",
    "                'Acceleration', 'Model Year', 'Origin']\n",
    "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
    "                      na_values = \"?\", comment='\\t',\n",
    "                      sep=\" \", skipinitialspace=True)\n",
    "\n",
    "dataset = raw_dataset.copy()\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.2. Limpieza de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nota que algunos datos hacen falta en este dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()  #cuántos datos faltan y en qué columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borrando las entradas completa que tienen datos faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como el atributo \"Origin\" contiene datos categórigos mas no numéricos, convertimos a one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = dataset.pop('Origin')  ## método pop() elimina la columna 'Origin' del fataset y lo reescribe. Además guarda la columna eliminada en origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin.unique() ## Categoría de origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \"Dummificación\" manual: OJO, no limina una de las categorías\n",
    "dataset['USA']    = (origin == 1)*1.0 ## (origin == 1) es un booleano que devuelve 0 o 1\n",
    "dataset['Europe'] = (origin == 2)*1.0 ## (origin == 2) es un booleano que devuelve 0 o 1\n",
    "dataset['Japan']  = (origin == 3)*1.0 ## (origin == 3) es un booleano que devuelve 0 o 1\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.3.Divide los datos en conjunto de entrenamiento y conjunto de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Otra forma diferente a \"train_test_split\" de sklearn para dividir los datos en entrenamiento y prueba\n",
    "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Matriz de diagramas de dispersión entre las columnas originalmente numéricas\n",
    "sns.pairplot(train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\", kind= \"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.5.Verifica las estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats = train_dataset.describe() ## Guarda el dataset con las estadísticas descriptivas\n",
    "train_stats.pop(\"MPG\")                 ## Elimina la columna correspondiente a la variable respuesta\n",
    "train_stats = train_stats.transpose()  ## Transpone el fataframe\n",
    "train_stats ## Nótese la diferencia de escalas en las variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.6.Separa el valor objetivo en atributo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_dataset.pop('MPG') ## Etiquetas para los datos de entrenamiento\n",
    "test_labels = test_dataset.pop('MPG')   ## Etiquetas para los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.7.Normaliza los Datos\n",
    "\n",
    "Este enfoque `NO` es recomendado porque no guarda la información de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## observe todas las medias cercanas a 0 y desviacines estándar a 1\n",
    "normed_test_data.describe().loc[[\"mean\", \"std\"],]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.8.Crea el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construye el modelo secuencial con una capa densamente conectada.\n",
    "# La capa de salida devuelve los valores consecutivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): ## Función auxiliar para construir y compilar la red\n",
    "    model = keras.Sequential(#---------------------------------------------- Sequential permite construir la aequitectura por capas\n",
    "        [                    #---------------------------------------------- layers permite especificar la información por capa. Dense significa totalmente conectada.\n",
    "              layers.Dense(  64 #------------------------------------------- Número de nodos (neuronas) de la capa\n",
    "                           , activation='relu' #---------------------------- función de activación de la capa\n",
    "                           , input_shape=[len(train_dataset.keys())] #------ Número de variables de la capa de entrada\n",
    "                             )\n",
    "            , layers.Dense(64, activation='relu') #------------------------- Segunda capa interna, también con RELU y 64 neuronas\n",
    "            , layers.Dense(1)]) #------------------------------------------- capa de salida, una neurona y función de activación LINEAR (por defecto)\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001) #------------------------ selección del algoritmo de optimización y tasa de aprendizaje (0.001)\n",
    "    model.compile( #-------------------------------------------------------- El método compile() Configura el modelo para entrenamiento.\n",
    "                  loss='mse', #--------------------------------------------- Elige la funcipon de pérdida  o costo (mse: Mean Square Error).\n",
    "                  optimizer=optimizer, #------------------------------------ Elige el algoritmo de optimización\n",
    "                  metrics=['mae', 'mse', 'mape']) #------------------------- Selecciona las métricas de desempeño\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.9.Verifica el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset.keys())) ## Número de variables de entrada: 9\n",
    "model.summary()\n",
    "# [ 9pesos + 1sesgo]x[64 neuronas] = 640\n",
    "# [64pesos + 1sesgo]x[64 neuronas] = 4160\n",
    "# [64pesos + 1sesgo]x[1  neurona]  = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llama el método model.predict colocando 10 muestras del conjunto de entrenamiento en un lote.\n",
    "# IMPORTANTE: En este punto, el modelo NO está entrenado, pero los pesos se han inicializado y es posible hacer predicciones, generalmente MALAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = normed_train_data[:10]\n",
    "example_result = model.predict(example_batch)\n",
    "example_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PESOS INICIALES\n",
    "model.get_weights()#[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.10.Entrena el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Coloca un punto (.) para indicar el proceso de entrenamiento al final de cada época (epoch)\n",
    "# Se crea la clase PrintDot, la cual hereda de la clase keras.callbacks.Callback\n",
    "class PrintDot(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if epoch % 100 == 0: print('') #-------------- imprime \" . \" por cada época y las agrupa en lotes de 100\n",
    "        print('.', end='')\n",
    "\n",
    "EPOCHS = 1000 #--------------------------------------- define el número de épocas\n",
    "\n",
    "history = model.fit( #-------------------------------- Inicia el entrenamineto y guarda el historial\n",
    "                    normed_train_data, #-------------- X_train\n",
    "                    train_labels, #------------------- Y_train\n",
    "                    epochs=EPOCHS,#------------------- épocas\n",
    "                    validation_split = 0.2, #--------- Proporción de datos para proceso de validación\n",
    "                    verbose=0, #---------------------- Silencia las notificaciones de progreso automático\n",
    "                    callbacks=[PrintDot()] #---------- Invoca la clase PrintDot para darle formato a las notificaciones de progreso automático\n",
    "                    )\n",
    "## Desempeño: Wall time: 1min 22s (CPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(\"....................................................................................................\"))\n",
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiza el rendimiento del proceso de entrenamiento usando las estadísticas en\n",
    "# el objeto \"history\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(history.history) #--- Crea un dataframe con la historia de entrenamiento\n",
    "hist['epoch'] = history.epoch        #---   Agrega una columna adicional con el índice de cafa época\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficando el error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Abs Error [MPG]')\n",
    "    plt.plot(hist['epoch'], hist['mae'],label='Error de Entrenamiento')\n",
    "    plt.plot(hist['epoch'], hist['val_mae'],label = 'Error de Validación')\n",
    "    plt.ylim([0,5])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Error [$MPG^2$]')\n",
    "    plt.plot(hist['epoch'], hist['mse'],label='Error de entrenamiento')\n",
    "    plt.plot(hist['epoch'], hist['val_mse'],label = 'Error de Validación')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Mean Square Percentage Error [$MAPE$]')\n",
    "    plt.plot(hist['epoch'], hist['mape'],label='Error de entrenamiento')\n",
    "    plt.plot(hist['epoch'], hist['val_mape'],label = 'Error de Validación')\n",
    "    plt.ylim([0,20])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al modificar el método model.fit, el entrenamiento se detiene automáticamente cuando la variación no mejora.\n",
    "# Utiliza EarlyStopping callback para verificar el proceso de entrenamiento en cada época.\n",
    "\n",
    "# Detener automáticamente el entrenamiento cuando no haya más mejoras con respecto al número\n",
    "# especificado de épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = build_model()\n",
    "\n",
    "# El parámetro 'patience' es la cantidad de épocas que se usará para verificar la mejora.\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
    "                    validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(history.epoch) ## se detuvo en la época 70."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.11.Verificar el rendimiento del modelo en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse, mape = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Mean absolute error del conjunto de evaluación: {:5.2f} MPG\".format(mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "print(round(mape,2), \"%\", sep=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 1.12. Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utilizamos el método \".predict\" para utilizar el modelo para hacer predicción\n",
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('Valores Reales [MPG]')\n",
    "plt.ylabel('Predicciones [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100]) ## para agregar la línea recta \"y = x\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(normed_test_data).flatten().shape#\n",
    "import numpy as np\n",
    "\n",
    "np.corrcoef(test_labels, test_predictions)[1,0] ## Alta correlación lineal entre lo obsevado y lo predicho es un buen indicador del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
