{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN using Tensor Flow Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcruz\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\mcruz\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.29 url/s]\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:01,  2.04 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.73 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.28 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  3.04 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.90 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.59 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.41 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00,  2.17 url/s]\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:01<00:01,  1.92 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:01<00:00,  2.86 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.86 url/s]\n",
      "\u001b[A\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.86 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:02<00:00,  2.86 url/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  2.86 url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:03<00:00,  1.22 file/s]\n",
      "Dl Size...: 100%|██████████| 10/10 [00:03<00:00,  3.04 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:03<00:00,  1.21 url/s]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\mcruz\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n",
      "dict_keys([Split('train'), Split('test')])\n"
     ]
    }
   ],
   "source": [
    "#Descargamos el dataset\n",
    "mnist_bldr = tfds.builder ('mnist')\n",
    "mnist_bldr.download_and_prepare()\n",
    "datasets = mnist_bldr.as_dataset(shuffle_files=False)\n",
    "print(datasets.keys())\n",
    "mnist_train_orig, mnist_test_orig = datasets['train'], datasets['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre procesado de datos\n",
    "mnist_train = mnist_train_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32)/255.0,\n",
    "                  tf.cast(item['label'], tf.int32)))\n",
    "\n",
    "mnist_test = mnist_test_orig.map(\n",
    "    lambda item: (tf.cast(item['image'], tf.float32) /255.0,\n",
    "                  tf.cast(item['label'], tf.int32)))\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "#mezclar dataset\n",
    "mnist_train = mnist_train.shuffle(buffer_size=BUFFER_SIZE,\n",
    "                                  reshuffle_each_iteration=False)\n",
    "\n",
    "#separar train y test datasets\n",
    "mnist_valid = mnist_train.take(10000).batch(BATCH_SIZE)\n",
    "mnist_train = mnist_train.skip(10000).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=32, kernel_size=(5, 5),\n",
    "    strides=(1, 1), padding='same',\n",
    "    data_format='channels_last',\n",
    "    name='conv_1', activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(\n",
    "    pool_size=(2, 2), name='pool_1'))\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(\n",
    "    filters=64, kernel_size=(5, 5),\n",
    "    strides=(1, 1), padding='same',\n",
    "    name='conv_2', activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), name='pool_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layer Sequential should implement `def compute_output_shape(self, input_shape)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_output_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m28\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mcruz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\layer.py:1055\u001b[0m, in \u001b[0;36mLayer.compute_output_shape\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mdefault\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_output_shape\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 1055\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m   1056\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should implement \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1057\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`def compute_output_shape(self, input_shape)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1058\u001b[0m     )\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Layer Sequential should implement `def compute_output_shape(self, input_shape)`."
     ]
    }
   ],
   "source": [
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "model.compute_output_shape(input_shape=(16, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Dense(\n",
    "    units=1024, name='fc_1',\n",
    "    activation='relu'))\n",
    "\n",
    "model.add(tf.keras.layers.Dropout(\n",
    "    rate=0.5))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(\n",
    "    units=10, name='fc_2',\n",
    "    activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy']) # same as `tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')`\n",
    "\n",
    "history = model.fit(mnist_train, epochs=NUM_EPOCHS,\n",
    "                    validation_data=mnist_valid,\n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "x_arr = np.arange(len(hist['loss'])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1,2,1)\n",
    "ax.plot(x_arr, hist['loss'],'-o', label='Train loss')\n",
    "ax.plot(x_arr, hist['val_loss'],'--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "ax.legend(fontsize=15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist['accuracy'], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist['val_accuracy'],'--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "#plt.savefig('images/15_12.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = model.evaluate(mnist_test.batch(20))\n",
    "print ('\\n test accuracy {:.2f}%'.format(test_results[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_test = next(iter(mnist_test.batch(12)))\n",
    "\n",
    "preds = model(batch_test[0])\n",
    "\n",
    "tf.print(preds.shape)\n",
    "preds = tf.argmax(preds, axis=1)\n",
    "print(preds)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "for i in range (12):\n",
    "  ax = fig.add_subplot(2, 6, i+1)\n",
    "  ax.set_xticks ([]); ax.set_yticks([])\n",
    "  img = batch_test[0][i,:,:, 0]\n",
    "  ax.imshow(img, cmap='gray_r')\n",
    "  ax.text(0.9, 0.1, '{}'.format(preds[i]),\n",
    "          size=15, color='blue',\n",
    "          horizontalalignment='center',\n",
    "          verticalalignment='center',\n",
    "          transform=ax.transAxes)\n",
    "\n",
    "#plt.savefig('images/15_13.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "  os.mkdir('models')\n",
    "\n",
    "model.save('models/mnist-cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
